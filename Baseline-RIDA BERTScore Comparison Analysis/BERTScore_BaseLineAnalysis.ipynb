{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQlr98G6XPEH"
      },
      "source": [
        "# 1- Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820ffc48",
        "outputId": "c43f39a1-9588-43f5-d3b0-ae40f8ae1bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.56.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.35.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2025.8.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install bert-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxlI3-ToL1yF",
        "outputId": "34b5f1ac-bbb2-494b-db98-f2661b67ad9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current working directory: /content/drive/My Drive/Colab Notebooks/BERTScore\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change the current directory to the specified folder\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/BERTScore'\n",
        "os.chdir(folder_path)\n",
        "\n",
        "# Verify the current directory\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b762bfb"
      },
      "source": [
        "# 1-Task\n",
        "Merge the text files located in the \"My Drive/Colab Notebooks/BERTScore/CS1/I1/PRI\", \"My Drive/Colab Notebooks/BERTScore/CS1/I1/RIDA\", \"My Drive/Colab Notebooks/BERTScore/CS1/I2/PRI\", and \"My Drive/Colab Notebooks/BERTScore/CS1/I2/RIDA\" folders, keeping track of the original folder for each merged section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bfad710"
      },
      "source": [
        "## Define base path and subfolders\n",
        "\n",
        "### Subtask:\n",
        "Define the base path to the BERTScore folder and the names of the case study and iteration subfolders.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3f2002e"
      },
      "source": [
        "**3-Reasoning**:\n",
        "Define the base path and the case study, iteration, and subfolder names as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a936f38"
      },
      "outputs": [],
      "source": [
        "# base_path = '/content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis'\n",
        "# cs_folder = 'CS1'\n",
        "# iterations = ['I1', 'I2']\n",
        "# subfolders = ['PRI', 'RIDA']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6d60005"
      },
      "source": [
        "## 7-Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The text files from four different folders (`My Drive/Colab Notebooks/BERTScore/CS1/I1/PRI`, `My Drive/Colab Notebooks/BERTScore/CS1/I1/RIDA`, `My Drive/Colab Notebooks/BERTScore/CS1/I2/PRI`, and `My Drive/Colab Notebooks/BERTScore/CS1/I2/RIDA`) were successfully read and their content merged.\n",
        "*   A Python function `read_and_merge_text_files` was created to handle reading multiple text files within a given folder.\n",
        "*   The merged content from each specific folder (I1/RIDA, I1/PRI, I2/RIDA, I2/PRI) was stored in separate variables (`rida_i1_content`, `pri_i1_content`, `rida_i2_content`, `pri_i2_content`).\n",
        "*   All the merged content was combined into a single list of dictionaries called `merged_data`, with each dictionary containing the `iteration` ('I1' or 'I2'), `subfolder` ('RIDA' or 'PRI'), and the actual `content`.\n",
        "*   The final combined `merged_data` was successfully saved as a JSON file named `merged_text_data.json` for further analysis.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The structured `merged_data` allows for easy filtering and analysis of text content based on its original iteration and subfolder.\n",
        "*   The saved JSON file can now be loaded and used as the input for subsequent natural language processing or text analysis tasks, such as BERTScore calculation between the PRI and RIDA content within each iteration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0d41fae"
      },
      "source": [
        "# Task\n",
        "Merge the text files located in the \"My Drive/Colab Notebooks/BERTScore/CS1/I1/PRI\", \"My Drive/Colab Notebooks/BERTScore/CS1/I1/RIDA\", \"My Drive/Colab Notebooks/BERTScore/CS1/I2/PRI\", and \"My Drive/Colab Notebooks/BERTScore/CS1/I2/RIDA\" folders, keeping track of the original folder for each merged section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6da60f57"
      },
      "source": [
        "## 8-Define base path and subfolders\n",
        "\n",
        "### Subtask:\n",
        "Define the base path to the BERTScore folder and the names of the case study and iteration subfolders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9309e3b6"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the base path and the case study, iteration, and subfolder names as instructed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8a5ccbb",
        "outputId": "0df4ad3f-2dbc-4ad8-ab85-de9ede19b310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Base path defined: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis\n",
            "Case studies to process: ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8', 'CS9', 'CS10']\n",
            "Iterations to process: ['I1', 'B1']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the base path to the BERTScore folder\n",
        "base_path = '/content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis'\n",
        "# Define the range of case studies and iterations\n",
        "case_studies = [f'CS{i}' for i in range(1, 11)] # CS1 to CS10\n",
        "# Updated iterations to compare I1 and B1\n",
        "iterations = ['I1', 'B1']\n",
        "subfolders = ['PRI', 'RIDA']\n",
        "\n",
        "# Change the current directory to the specified folder\n",
        "# This step is optional but can be helpful for managing file paths\n",
        "# os.chdir(base_path)\n",
        "\n",
        "# Verify the base path and defined ranges\n",
        "print(f\"Base path defined: {base_path}\")\n",
        "print(f\"Case studies to process: {case_studies}\")\n",
        "print(f\"Iterations to process: {iterations}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3412ba24"
      },
      "source": [
        "## 9-Create a function to read and merge files\n",
        "\n",
        "### Subtask:\n",
        "Create a function that takes a folder path as input, reads all the text files within that folder, and merges their content into a single string or a list of strings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edfff53c"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `read_and_merge_text_files` function as described in the instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b8e2e79"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_and_merge_text_files(folder_path):\n",
        "    \"\"\"\n",
        "    Reads all text files within a folder and merges their content.\n",
        "\n",
        "    Args:\n",
        "        folder_path: The path to the folder containing the text files.\n",
        "\n",
        "    Returns:\n",
        "        A list of strings, where each string is the content of a text file.\n",
        "    \"\"\"\n",
        "    merged_content = []\n",
        "    try:\n",
        "        # Ensure the folder exists before trying to list its contents\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"Folder not found: {folder_path}\")\n",
        "            return None\n",
        "\n",
        "        # Get the list of files and sort them alphabetically/numerically\n",
        "        filenames = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and f.endswith('.txt')]\n",
        "        filenames.sort() # Sort the filenames\n",
        "\n",
        "        for filename in filenames:\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                merged_content.append(f.read())\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading files from {folder_path}: {e}\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "    return merged_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b3120ef"
      },
      "source": [
        "## 10-Process iteration 1\n",
        "\n",
        "### Subtask:\n",
        "Use the function to read and merge the RIDA files from Iteration 1, and then the PRI files from Iteration 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d0f136b"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct the full paths for the RIDA and PRI folders for Iteration 1 and call the `read_and_merge_text_files` function for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb5386b4"
      },
      "outputs": [],
      "source": [
        "# # Construct the full path to the RIDA folder for Iteration 1\n",
        "# rida_i1_folder_path = os.path.join(base_path, cs_folder, iterations[0], subfolders[1])\n",
        "\n",
        "# # Call the function to read and merge RIDA files from Iteration 1\n",
        "# rida_i1_content = read_and_merge_text_files(rida_i1_folder_path)\n",
        "\n",
        "# # Construct the full path to the PRI folder for Iteration 1\n",
        "# pri_i1_folder_path = os.path.join(base_path, cs_folder, iterations[0], subfolders[0])\n",
        "\n",
        "# # Call the function to read and merge PRI files from Iteration 1\n",
        "# pri_i1_content = read_and_merge_text_files(pri_i1_folder_path)\n",
        "\n",
        "# # Print the number of files merged and the first 100 characters for verification\n",
        "# print(f\"Number of RIDA I1 files merged: {len(rida_i1_content) if rida_i1_content else 0}\")\n",
        "# print(f\"Merged RIDA I1 content (first 100 chars): {rida_i1_content[0][:100] if rida_i1_content and rida_i1_content[0] else 'None'}\")\n",
        "\n",
        "# print(f\"\\nNumber of PRI I1 files merged: {len(pri_i1_content) if pri_i1_content else 0}\")\n",
        "# print(f\"Merged PRI I1 content (first 100 chars): {pri_i1_content[0][:100] if pri_i1_content and pri_i1_content[0] else 'None'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "744d81a9"
      },
      "source": [
        "## 11-Process iteration 2\n",
        "\n",
        "### Subtask:\n",
        "Use the function to read and merge the RIDA files from Iteration 2, and then the PRI files from Iteration 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8923cc0c"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct the paths for RIDA and PRI files for Iteration 2, then call the `read_and_merge_text_files` function for each path to merge the content and store the results in the specified variables. Finally, print the first 100 characters of the merged content for verification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6921f88"
      },
      "outputs": [],
      "source": [
        "# Construct the full path to the RIDA folder for Iteration 2\n",
        "# rida_i2_folder_path = os.path.join(base_path, cs_folder, iterations[1], subfolders[1])\n",
        "\n",
        "# # Call the function to read and merge RIDA files from Iteration 2\n",
        "# rida_i2_content = read_and_merge_text_files(rida_i2_folder_path)\n",
        "\n",
        "# # Construct the full path to the PRI folder for Iteration 2\n",
        "# pri_i2_folder_path = os.path.join(base_path, cs_folder, iterations[1], subfolders[0])\n",
        "\n",
        "# # Call the function to read and merge PRI files from Iteration 2\n",
        "# pri_i2_content = read_and_merge_text_files(pri_i2_folder_path)\n",
        "\n",
        "# # Print the number of files merged and the first 100 characters for verification\n",
        "# print(f\"Number of RIDA I2 files merged: {len(rida_i2_content) if rida_i2_content else 0}\")\n",
        "# print(f\"Merged RIDA I2 content (first 100 chars): {rida_i2_content[0][:100] if rida_i2_content and rida_i2_content[0] else 'None'}\")\n",
        "\n",
        "# print(f\"\\nNumber of PRI I2 files merged: {len(pri_i2_content) if pri_i2_content else 0}\")\n",
        "# print(f\"Merged PRI I2 content (first 100 chars): {pri_i2_content[0][:100] if pri_i2_content and pri_i2_content[0] else 'None'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76ec84db"
      },
      "source": [
        "## 12-Combine iteration 1 and 2 results\n",
        "\n",
        "### Subtask:\n",
        "Combine the merged contents from Iteration 1 and Iteration 2, keeping track of which content belongs to which iteration and subfolder (RIDA or PRI)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "212a3549"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to combine the merged content from Iteration 1 and Iteration 2, keeping track of the iteration and subfolder. This involves iterating through the content lists for each iteration and subfolder (RIDA and PRI) and appending dictionaries with the relevant information to a new list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8d45c9c"
      },
      "outputs": [],
      "source": [
        "# merged_data = []\n",
        "\n",
        "# # Process Iteration 1 RIDA content\n",
        "# if rida_i1_content:\n",
        "#     for content in rida_i1_content:\n",
        "#         merged_data.append({\n",
        "#             'iteration': 'I1',\n",
        "#             'subfolder': 'RIDA',\n",
        "#             'content': content\n",
        "#         })\n",
        "\n",
        "# # Process Iteration 1 PRI content\n",
        "# if pri_i1_content:\n",
        "#     for content in pri_i1_content:\n",
        "#         merged_data.append({\n",
        "#             'iteration': 'I1',\n",
        "#             'subfolder': 'PRI',\n",
        "#             'content': content\n",
        "#         })\n",
        "\n",
        "# # Process Iteration 2 RIDA content\n",
        "# if rida_i2_content:\n",
        "#     for content in rida_i2_content:\n",
        "#         merged_data.append({\n",
        "#             'iteration': 'I2',\n",
        "#             'subfolder': 'RIDA',\n",
        "#             'content': content\n",
        "#         })\n",
        "\n",
        "# # Process Iteration 2 PRI content\n",
        "# if pri_i2_content:\n",
        "#     for content in pri_i2_content:\n",
        "#         merged_data.append({\n",
        "#             'iteration': 'I2',\n",
        "#             'subfolder': 'PRI',\n",
        "#             'content': content\n",
        "#         })\n",
        "\n",
        "# # Print the first few entries to verify\n",
        "# print(\"First few entries of merged_data:\")\n",
        "# for entry in merged_data[:5]:\n",
        "#     print(entry)\n",
        "\n",
        "# print(f\"\\nTotal number of merged entries: {len(merged_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f01db73"
      },
      "source": [
        "## 13-Save the merged data\n",
        "\n",
        "### Subtask:\n",
        "Save the combined data into a new file or data structure for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25067c04"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the `merged_data` list to a JSON file for persistent storage and easy retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "091d257c"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Define the file path for saving the merged data\n",
        "# output_file_path = 'merged_text_data.json'\n",
        "\n",
        "# # Save the merged_data to a JSON file\n",
        "# try:\n",
        "#     with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "#         json.dump(merged_data, f, indent=4)\n",
        "#     print(f\"Merged data successfully saved to {output_file_path}\")\n",
        "# except IOError as e:\n",
        "#     print(f\"Error saving data to {output_file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b613a2d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* The text files from four different folders (`My Drive/Colab Notebooks/BERTScore/CS1/I1/PRI`, `My Drive/Colab Notebooks/BERTScore/CS1/I1/RIDA`, `My Drive/Colab Notebooks/BERTScore/CS1/I2/PRI`, and `My Drive/Colab Notebooks/BERTScore/CS1/I2/RIDA`) were successfully read and their content merged.\n",
        "* A Python function `read_and_merge_text_files` was created to handle reading multiple text files within a given folder.\n",
        "* The merged content from each specific folder (I1/RIDA, I1/PRI, I2/RIDA, I2/PRI) was stored in separate variables (`rida_i1_content`, `pri_i1_content`, `rida_i2_content`, `pri_i2_content`).\n",
        "* All the merged content was combined into a single list of dictionaries called `merged_data`, with each dictionary containing the `iteration` ('I1' or 'I2'), `subfolder` ('RIDA' or 'PRI'), and the actual `content`.\n",
        "* The final combined `merged_data` was successfully saved as a JSON file named `merged_text_data.json` for further analysis.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "* The structured `merged_data` allows for easy filtering and analysis of text content based on its original iteration and subfolder.\n",
        "* The saved JSON file can now be loaded and used as the input for subsequent natural language processing or text analysis tasks, such as BERTScore calculation between the PRI and RIDA content within each iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5859bd93"
      },
      "source": [
        "## 14-Display Merged Data\n",
        "\n",
        "### Subtask:\n",
        "Load the saved JSON file and display its content to verify the merging process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa0dd4e3"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the `merged_text_data.json` file and print its content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e42cb29"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Define the file path\n",
        "# output_file_path = 'merged_text_data.json'\n",
        "\n",
        "# # Load the merged data from the JSON file\n",
        "# try:\n",
        "#     with open(output_file_path, 'r', encoding='utf-8') as f:\n",
        "#         loaded_merged_data = json.load(f)\n",
        "\n",
        "#     # Display the loaded data (first 10 entries for brevity)\n",
        "#     print(\"Content of merged_text_data.json (first 10 entries):\")\n",
        "#     for entry in loaded_merged_data[:10]:\n",
        "#         print(entry)\n",
        "\n",
        "#     print(f\"\\nTotal number of entries in the loaded data: {len(loaded_merged_data)}\")\n",
        "\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: The file {output_file_path} was not found.\")\n",
        "# except json.JSONDecodeError:\n",
        "#     print(f\"Error: Could not decode JSON from {output_file_path}.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27e95f77"
      },
      "source": [
        "# Task\n",
        "Calculate BERTScore between iterations (I1 vs I2, I1 vs I3, I2 vs I3) for both PRI and RIDA content within each case study (CS1 to CS10) using the data from \"merged_text_data.json\". Display the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3779e24c"
      },
      "source": [
        "## 16-Organize data by case study and iteration\n",
        "\n",
        "### Subtask:\n",
        "Restructure the loaded data to easily access the content for each case study, iteration, and subfolder (PRI/RIDA).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e637d230"
      },
      "source": [
        "**Reasoning**:\n",
        "Restructure the loaded `merged_data` into a nested dictionary `organized_data` keyed by iteration and subfolder to facilitate easy access for BERTScore calculation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2e62003"
      },
      "outputs": [],
      "source": [
        "# organized_data = {}\n",
        "\n",
        "# # Iterate through each entry in the merged_data list\n",
        "# for entry in merged_data:\n",
        "#     iteration = entry['iteration']\n",
        "#     subfolder = entry['subfolder']\n",
        "#     content = entry['content']\n",
        "\n",
        "#     # Create nested dictionaries if keys do not exist\n",
        "#     if iteration not in organized_data:\n",
        "#         organized_data[iteration] = {}\n",
        "\n",
        "#     if subfolder not in organized_data[iteration]:\n",
        "#         organized_data[iteration][subfolder] = []\n",
        "\n",
        "#     # Append the content to the corresponding list\n",
        "#     organized_data[iteration][subfolder].append(content)\n",
        "\n",
        "# # Print the keys of the organized_data to verify the structure\n",
        "# print(\"Keys of organized_data:\", organized_data.keys())\n",
        "\n",
        "# # Print the number of entries in each subfolder for a sample iteration (e.g., I1)\n",
        "# if 'I1' in organized_data:\n",
        "#     print(\"\\nNumber of entries in I1 subfolders:\")\n",
        "#     for subfolder, content_list in organized_data['I1'].items():\n",
        "#         print(f\"  {subfolder}: {len(content_list)} entries\")\n",
        "# else:\n",
        "#     print(\"\\nNo data found for Iteration I1 in organized_data.\")\n",
        "\n",
        "# # Print the number of entries in each subfolder for a sample iteration (e.g., I2)\n",
        "# if 'I2' in organized_data:\n",
        "#     print(\"\\nNumber of entries in I2 subfolders:\")\n",
        "#     for subfolder, content_list in organized_data['I2'].items():\n",
        "#         print(f\"  {subfolder}: {len(content_list)} entries\")\n",
        "# else:\n",
        "#     print(\"\\nNo data found for Iteration I2 in organized_data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a5c1144"
      },
      "source": [
        "## 17-Define bertscore calculation function\n",
        "\n",
        "### Subtask:\n",
        "Create a function to calculate BERTScore between two lists of texts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7899cb0"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `calculate_bert_score` function as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a17d18f"
      },
      "outputs": [],
      "source": [
        "# from bert_score import score\n",
        "\n",
        "# def calculate_bert_score(candidate_texts, reference_texts):\n",
        "#     \"\"\"\n",
        "#     Calculates BERTScore between two lists of texts.\n",
        "\n",
        "#     Args:\n",
        "#         candidate_texts: A list of strings representing the candidate texts.\n",
        "#         reference_texts: A list of strings representing the reference texts.\n",
        "\n",
        "#     Returns:\n",
        "#         A tuple containing three tensors: precision, recall, and F1 score.\n",
        "#     \"\"\"\n",
        "#     P, R, F1 = score(candidate_texts, reference_texts, lang='en', model_type='bert-base-uncased')\n",
        "#     return P, R, F1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtL6bfwdRaQv"
      },
      "source": [
        "-------------------------------------------------------------------------------------------------\n",
        "START AGAIN\n",
        "-------------------------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe9ec646"
      },
      "source": [
        "## 18-Load merged data\n",
        "\n",
        "### Subtask:\n",
        "Load the `merged_text_data.json` file into a Python variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a4a6774"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the merged data from the JSON file into a Python variable, including error handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f301d210"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Define the file path\n",
        "# output_file_path = 'merged_text_data.json'\n",
        "\n",
        "# # Load the merged data from the JSON file\n",
        "# try:\n",
        "#     with open(output_file_path, 'r', encoding='utf-8') as f:\n",
        "#         merged_data = json.load(f)\n",
        "\n",
        "#     print(f\"Merged data successfully loaded from {output_file_path}\")\n",
        "\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: The file {output_file_path} was not found.\")\n",
        "# except json.JSONDecodeError:\n",
        "#     print(f\"Error: Could not decode JSON from {output_file_path}.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An unexpected error occurred during loading: {e}\")\n",
        "\n",
        "# # Restructure the loaded data to easily access the content for each case study, iteration, and subfolder (PRI/RIDA).\n",
        "# organized_data = {}\n",
        "\n",
        "# # Iterate through each entry in the merged_data list\n",
        "# for entry in merged_data:\n",
        "#     iteration = entry['iteration']\n",
        "#     subfolder = entry['subfolder']\n",
        "#     content = entry['content']\n",
        "\n",
        "#     # Create nested dictionaries if keys do not exist\n",
        "#     if iteration not in organized_data:\n",
        "#         organized_data[iteration] = {}\n",
        "\n",
        "#     if subfolder not in organized_data[iteration]:\n",
        "#         organized_data[iteration][subfolder] = []\n",
        "\n",
        "#     # Append the content to the corresponding list\n",
        "#     organized_data[iteration][subfolder].append(content)\n",
        "\n",
        "# # Print the keys of the organized_data to verify the structure\n",
        "# print(\"Keys of organized_data:\", organized_data.keys())\n",
        "\n",
        "# # Print the number of entries in each subfolder for a sample iteration (e.g., I1)\n",
        "# if 'I1' in organized_data:\n",
        "#     print(\"\\nNumber of entries in I1 subfolders:\")\n",
        "#     for subfolder, content_list in organized_data['I1'].items():\n",
        "#         print(f\"  {subfolder}: {len(content_list)} entries\")\n",
        "# else:\n",
        "#     print(\"\\nNo data found for Iteration I1 in organized_data.\")\n",
        "\n",
        "# # Print the number of entries in each subfolder for a sample iteration (e.g., I2)\n",
        "# if 'I2' in organized_data:\n",
        "#     print(\"\\nNumber of entries in I2 subfolders:\")\n",
        "#     for subfolder, content_list in organized_data['I2'].items():\n",
        "#         print(f\"  {subfolder}: {len(content_list)} entries\")\n",
        "# else:\n",
        "#     print(\"\\nNo data found for Iteration I2 in organized_data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "321201cf"
      },
      "source": [
        "## 20-Define bertscore calculation function\n",
        "\n",
        "### Subtask:\n",
        "Create a function to calculate BERTScore between two lists of texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "490512d1"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `calculate_bert_score` function as described in the instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa1edac9"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "def calculate_bert_score(candidate_texts, reference_texts):\n",
        "    \"\"\"\n",
        "    Calculates BERTScore between two lists of texts.\n",
        "\n",
        "    Args:\n",
        "        candidate_texts: A list of strings representing the candidate texts.\n",
        "        reference_texts: A list of strings representing the reference texts.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing three tensors: precision, recall, and F1 score.\n",
        "    \"\"\"\n",
        "    # P, R, F1 = score(candidate_texts, reference_texts, lang='en', model_type='bert-base-uncased', idf=True)\n",
        "    P, R, F1 = score(candidate_texts, reference_texts, lang='en', model_type='roberta-large')\n",
        "\n",
        "\n",
        "    return P, R, F1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89b3e7b2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The text content from PRI and RIDA subfolders for each iteration within each case study was successfully combined into a single string. All combined strings across case studies and iterations had a length of 92309 characters.\n",
        "*   BERT scores (Precision, Recall, and F1) were calculated for the iteration pairs I1 vs I2, I1 vs I3, and I2 vs I3 within each case study using the combined PRI and RIDA content.\n",
        "*   The calculated BERT scores for each case study and iteration comparison were successfully organized into a pandas DataFrame with columns for 'Case Study', 'Comparison', 'Precision (Combined)', 'Recall (Combined)', and 'F1 Score (Combined)'.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Further analysis could involve comparing the BERT scores across case studies and iteration pairs to identify trends in text similarity development over iterations.\n",
        "*   Consider visualizing the BERT scores (e.g., using bar charts) to make the comparisons between case studies and iteration pairs more intuitive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75e04676"
      },
      "source": [
        "## 27-Inspect Organized Data for a Case Study with Score Variations\n",
        "\n",
        "### Subtask:\n",
        "Inspect the content of the `organized_data` dictionary for a case study where BERT scores were not consistently 1.0 to check if the content across iterations is identical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d49f66c9"
      },
      "source": [
        "**Reasoning**:\n",
        "Access the content for a specific case study and its iterations from the `organized_data` dictionary and print parts of the content to compare them and identify potential differences that could explain the unexpected BERTScore results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c76f9cdc"
      },
      "outputs": [],
      "source": [
        "# # Choose a case study where you observed BERTScore variations (e.g., CS2)\n",
        "# case_study_to_inspect = 'CS2'\n",
        "\n",
        "# if case_study_to_inspect in organized_data:\n",
        "#     print(f\"Inspecting data for Case Study: {case_study_to_inspect}\\n\")\n",
        "\n",
        "#     for iteration in iterations:\n",
        "#         if iteration in organized_data[case_study_to_inspect]:\n",
        "#             print(f\"Content for {case_study_to_inspect}/{iteration}/PRI (first 500 chars):\")\n",
        "#             # Accessing the first file's content in the PRI subfolder\n",
        "#             pri_content = organized_data[case_study_to_inspect][iteration].get('PRI', [])\n",
        "#             if pri_content:\n",
        "#                 print(pri_content[0][:500])\n",
        "#             else:\n",
        "#                 print(\"No PRI content found.\")\n",
        "\n",
        "#             print(f\"\\nContent for {case_study_to_inspect}/{iteration}/RIDA (first 500 chars):\")\n",
        "#             # Accessing the first file's content in the RIDA subfolder\n",
        "#             rida_content = organized_data[case_study_to_inspect][iteration].get('RIDA', [])\n",
        "#             if rida_content:\n",
        "#                 print(rida_content[0][:500])\n",
        "#             else:\n",
        "#                  print(\"No RIDA content found.\")\n",
        "\n",
        "#             print(\"-\" * 50) # Separator for clarity\n",
        "#         else:\n",
        "#             print(f\"No data found for {case_study_to_inspect}/{iteration}\")\n",
        "# else:\n",
        "#     print(f\"Case Study '{case_study_to_inspect}' not found in organized_data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa8f1958"
      },
      "source": [
        "# Task\n",
        "Calculate the BERTScore between iterations (I1 vs I2, I1 vs I3, I2 vs I3) for each case study (CS1 to CS10). For each iteration within a case study, combine the text content of all PRI and RIDA files before calculating the BERTScore. Present the results in a table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56a74c16"
      },
      "source": [
        "## 28-Iterate and merge files by case study and iteration\n",
        "\n",
        "### Subtask:\n",
        "Iterate through each case study and iteration. For each iteration, read and combine the content from both the PRI and RIDA subfolders into a single text string."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7f930e9"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through each case study and iteration, read and combine the content from both the PRI and RIDA subfolders, and store the combined content in a dictionary keyed by case study and iteration. This directly addresses the current subtask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82d4839a",
        "outputId": "6c3d2f08-5f35-4dd1-9ffb-9ade26d32781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS1/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS1/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS1/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS1/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS2/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS2/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS2/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS2/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS3/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS3/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS3/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS3/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS4/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS4/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS4/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS4/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS5/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS5/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS5/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS5/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS6/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS6/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS6/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS6/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS7/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS7/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS7/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS7/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS8/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS8/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS8/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS8/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS9/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS9/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS9/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS9/B1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS10/I1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS10/I1/RIDA\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS10/B1/PRI\n",
            "Processing folder: /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/CS10/B1/RIDA\n",
            "\n",
            "Structure and size of combined_data:\n",
            "Case Study: CS1\n",
            "  Iteration: I1, Content length: 92309 characters\n",
            "  Iteration: B1, Content length: 50210 characters\n",
            "Case Study: CS2\n",
            "  Iteration: I1, Content length: 82820 characters\n",
            "  Iteration: B1, Content length: 72930 characters\n",
            "Case Study: CS3\n",
            "  Iteration: I1, Content length: 71137 characters\n",
            "  Iteration: B1, Content length: 70013 characters\n",
            "Case Study: CS4\n",
            "  Iteration: I1, Content length: 71170 characters\n",
            "  Iteration: B1, Content length: 70013 characters\n",
            "Case Study: CS5\n",
            "  Iteration: I1, Content length: 73457 characters\n",
            "  Iteration: B1, Content length: 60590 characters\n",
            "Case Study: CS6\n",
            "  Iteration: I1, Content length: 70364 characters\n",
            "  Iteration: B1, Content length: 67713 characters\n",
            "Case Study: CS7\n",
            "  Iteration: I1, Content length: 86283 characters\n",
            "  Iteration: B1, Content length: 67713 characters\n",
            "Case Study: CS8\n",
            "  Iteration: I1, Content length: 77084 characters\n",
            "  Iteration: B1, Content length: 82867 characters\n",
            "Case Study: CS9\n",
            "  Iteration: I1, Content length: 73335 characters\n",
            "  Iteration: B1, Content length: 82924 characters\n",
            "Case Study: CS10\n",
            "  Iteration: I1, Content length: 90780 characters\n",
            "  Iteration: B1, Content length: 82214 characters\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "combined_data = {}\n",
        "\n",
        "# Iterate through each case study\n",
        "for cs_folder in case_studies:\n",
        "    combined_data[cs_folder] = {}\n",
        "    # Iterate through each iteration (I1 and B1)\n",
        "    for iteration in iterations:\n",
        "        iteration_content = []\n",
        "        # Iterate through each subfolder (PRI and RIDA)\n",
        "        for subfolder in subfolders:\n",
        "            folder_path = os.path.join(base_path, cs_folder, iteration, subfolder)\n",
        "            print(f\"Processing folder: {folder_path}\") # Added print statement\n",
        "            content_list = read_and_merge_text_files(folder_path)\n",
        "\n",
        "            # If content was successfully read, extend the iteration_content list\n",
        "            if content_list is not None:\n",
        "                iteration_content.extend(content_list)\n",
        "            else:\n",
        "                print(f\"No content found or error reading from {folder_path}\") # Added print statement\n",
        "\n",
        "        # Combine all content for the current iteration into a single string\n",
        "        combined_data[cs_folder][iteration] = \"\\n\".join(iteration_content)\n",
        "\n",
        "# Print the structure and size of the combined_data for verification\n",
        "print(\"\\nStructure and size of combined_data:\")\n",
        "for cs, iter_data in combined_data.items():\n",
        "    print(f\"Case Study: {cs}\")\n",
        "    for iteration, content in iter_data.items():\n",
        "        print(f\"  Iteration: {iteration}, Content length: {len(content)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f66f6296"
      },
      "source": [
        "## 29-Calculate bert scores for each case study and iteration pair\n",
        "\n",
        "### Subtask:\n",
        "Iterate through each case study and calculate BERT scores for the desired iteration pairs (I1 vs I2, I1 vs I3, I2 vs I3) using the combined PRI and RIDA content for each iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca4e41eb"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the case studies and iteration pairs, retrieve the combined content for each iteration, calculate the BERTScore using the defined function with the combined content as input, and store the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fff82402",
        "outputId": "05c39aa1-1aa3-4877-ffcf-09296d593ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating BERTScore for CS1, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.8059, 0.8513, 0.8279\n",
            "\n",
            "Calculating BERTScore for CS2, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.8391, 0.8491, 0.8441\n",
            "\n",
            "Calculating BERTScore for CS3, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.8204, 0.8281, 0.8242\n",
            "\n",
            "Calculating BERTScore for CS4, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.7953, 0.8114, 0.8033\n",
            "\n",
            "Calculating BERTScore for CS5, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.8231, 0.8444, 0.8336\n",
            "\n",
            "Calculating BERTScore for CS6, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.8184, 0.8257, 0.8220\n",
            "\n",
            "Calculating BERTScore for CS7, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.7977, 0.8044, 0.8010\n",
            "\n",
            "Calculating BERTScore for CS8, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.8115, 0.8305, 0.8209\n",
            "\n",
            "Calculating BERTScore for CS9, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.8248, 0.8467, 0.8356\n",
            "\n",
            "Calculating BERTScore for CS10, B1 vs I1 (Combined PRI and RIDA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  BERTScore (P, R, F1): 0.8252, 0.8492, 0.8370\n"
          ]
        }
      ],
      "source": [
        "# Define the iteration pairs to compare (only I1 vs B1)\n",
        "#iteration_pairs = [('I1', 'B1')]\n",
        "iteration_pairs = [('B1', 'I1')]\n",
        "\n",
        "# Initialize an empty dictionary to store the calculated scores\n",
        "bert_scores_results_combined = {}\n",
        "\n",
        "# Iterate through each case study\n",
        "for case_study in case_studies:\n",
        "    bert_scores_results_combined[case_study] = {}\n",
        "    # Iterate through the iteration pairs (only I1 vs B1)\n",
        "    for iter1, iter2 in iteration_pairs:\n",
        "        # Get the combined content for the current iteration pair for the current case study\n",
        "        content1 = combined_data.get(case_study, {}).get(iter1, \"\")\n",
        "        content2 = combined_data.get(case_study, {}).get(iter2, \"\")\n",
        "\n",
        "        # Ensure both strings have content before calculating BERTScore\n",
        "        if content1 and content2:\n",
        "            print(f\"\\nCalculating BERTScore for {case_study}, {iter1} vs {iter2} (Combined PRI and RIDA)...\")\n",
        "            # Calculate BERTScore. Pass the single combined string for each iteration within a list.\n",
        "            try:\n",
        "                P, R, F1 = calculate_bert_score([content1], [content2])\n",
        "\n",
        "                # Store the results. .mean() is used to get a single score for each metric\n",
        "                bert_scores_results_combined[case_study][f'{iter1}_vs_{iter2}'] = {\n",
        "                    'precision': P.mean().item(),\n",
        "                    'recall': R.mean().item(),\n",
        "                    'f1': F1.mean().item()\n",
        "                }\n",
        "                print(f\"  BERTScore (P, R, F1): {P.mean().item():.4f}, {R.mean().item():.4f}, {F1.mean().item():.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error calculating BERTScore for {case_study}, {iter1} vs {iter2}: {e}\")\n",
        "                # Store None or an error indicator if calculation fails\n",
        "                bert_scores_results_combined[case_study][f'{iter1}_vs_{iter2}'] = None\n",
        "\n",
        "        else:\n",
        "            print(f\"\\nSkipping BERTScore calculation for {case_study}, {iter1} vs {iter2} due to missing combined content.\")\n",
        "\n",
        "# The bert_scores_results_combined dictionary now contains the calculated scores for combined content.\n",
        "# The next step is to present or save these results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d88d082f"
      },
      "source": [
        "## 30-Store and present results\n",
        "\n",
        "### Subtask:\n",
        "Store the calculated BERT scores in a structured format and display them as a table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75c23614"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the nested `bert_scores_results_combined` dictionary into a pandas DataFrame and display the DataFrame as a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "e19f305f",
        "outputId": "c657faf3-8100-4c12-aec1-48a8abe7d95d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Case Study Comparison  Precision (Combined)  Recall (Combined)  \\\n",
              "0        CS1   B1_vs_I1              0.828892           0.848880   \n",
              "1        CS2   B1_vs_I1              0.839137           0.849103   \n",
              "2        CS3   B1_vs_I1              0.820351           0.828075   \n",
              "3        CS4   B1_vs_I1              0.795311           0.811406   \n",
              "4        CS5   B1_vs_I1              0.823095           0.844350   \n",
              "5        CS6   B1_vs_I1              0.818403           0.825697   \n",
              "6        CS7   B1_vs_I1              0.797742           0.804377   \n",
              "7        CS8   B1_vs_I1              0.811500           0.830512   \n",
              "8        CS9   B1_vs_I1              0.824759           0.846670   \n",
              "9       CS10   B1_vs_I1              0.825173           0.849242   \n",
              "\n",
              "   F1 Score (Combined)  \n",
              "0             0.838767  \n",
              "1             0.844091  \n",
              "2             0.824195  \n",
              "3             0.803278  \n",
              "4             0.833588  \n",
              "5             0.822034  \n",
              "6             0.801046  \n",
              "7             0.820896  \n",
              "8             0.835571  \n",
              "9             0.837035  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd39cd27-2d72-47ea-b8a4-355bf8f71b42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Case Study</th>\n",
              "      <th>Comparison</th>\n",
              "      <th>Precision (Combined)</th>\n",
              "      <th>Recall (Combined)</th>\n",
              "      <th>F1 Score (Combined)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CS1</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.828892</td>\n",
              "      <td>0.848880</td>\n",
              "      <td>0.838767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CS2</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.839137</td>\n",
              "      <td>0.849103</td>\n",
              "      <td>0.844091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CS3</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.820351</td>\n",
              "      <td>0.828075</td>\n",
              "      <td>0.824195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CS4</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.795311</td>\n",
              "      <td>0.811406</td>\n",
              "      <td>0.803278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CS5</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.823095</td>\n",
              "      <td>0.844350</td>\n",
              "      <td>0.833588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CS6</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.818403</td>\n",
              "      <td>0.825697</td>\n",
              "      <td>0.822034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CS7</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.797742</td>\n",
              "      <td>0.804377</td>\n",
              "      <td>0.801046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CS8</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.811500</td>\n",
              "      <td>0.830512</td>\n",
              "      <td>0.820896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CS9</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.824759</td>\n",
              "      <td>0.846670</td>\n",
              "      <td>0.835571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CS10</td>\n",
              "      <td>B1_vs_I1</td>\n",
              "      <td>0.825173</td>\n",
              "      <td>0.849242</td>\n",
              "      <td>0.837035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd39cd27-2d72-47ea-b8a4-355bf8f71b42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd39cd27-2d72-47ea-b8a4-355bf8f71b42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd39cd27-2d72-47ea-b8a4-355bf8f71b42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4a35392c-2bae-4dff-a6e8-25ead576a228\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a35392c-2bae-4dff-a6e8-25ead576a228')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4a35392c-2bae-4dff-a6e8-25ead576a228 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d936a1cc-0784-4e8b-aef4-0ffe96fe2a01\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bert_scores_combined_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d936a1cc-0784-4e8b-aef4-0ffe96fe2a01 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bert_scores_combined_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bert_scores_combined_df",
              "summary": "{\n  \"name\": \"bert_scores_combined_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Case Study\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"CS9\",\n          \"CS2\",\n          \"CS6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comparison\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"B1_vs_I1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision (Combined)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0135800579657113,\n        \"min\": 0.7953107953071594,\n        \"max\": 0.8391372561454773,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8247588872909546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall (Combined)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01651053626865652,\n        \"min\": 0.8043773174285889,\n        \"max\": 0.8492419123649597,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.846670389175415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score (Combined)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014701545285276752,\n        \"min\": 0.8010456562042236,\n        \"max\": 0.8440907001495361,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8355709910392761\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create an empty list to store the data for the DataFrame\n",
        "table_data_combined = []\n",
        "\n",
        "# Iterate through the bert_scores_results_combined dictionary\n",
        "for case_study, scores_by_iteration in bert_scores_results_combined.items():\n",
        "    if scores_by_iteration:\n",
        "        for iteration_pair, scores in scores_by_iteration.items():\n",
        "            if scores:\n",
        "                # Append a row to the table_data_combined list\n",
        "                table_data_combined.append({\n",
        "                    'Case Study': case_study,\n",
        "                    'Comparison': iteration_pair,\n",
        "                    'Precision (Combined)': scores['precision'],\n",
        "                    'Recall (Combined)': scores['recall'],\n",
        "                    'F1 Score (Combined)': scores['f1']\n",
        "                })\n",
        "            else:\n",
        "                # Append a row indicating calculation failed\n",
        "                 table_data_combined.append({\n",
        "                    'Case Study': case_study,\n",
        "                    'Comparison': iteration_pair,\n",
        "                    'Precision (Combined)': 'N/A',\n",
        "                    'Recall (Combined)': 'N/A',\n",
        "                    'F1 Score (Combined)': 'N/A'\n",
        "                })\n",
        "\n",
        "\n",
        "# Create a pandas DataFrame from the list of data\n",
        "bert_scores_combined_df = pd.DataFrame(table_data_combined)\n",
        "\n",
        "# Display the DataFrame\n",
        "display(bert_scores_combined_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71a69f3d"
      },
      "source": [
        "## 31-Save BERTScore results to Google Drive\n",
        "\n",
        "### Subtask:\n",
        "Save the `bert_scores_combined_df` DataFrame to an Excel file in the specified Google Drive folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47cf7482"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the `to_excel` method of the pandas DataFrame to save the results to an Excel file in the user's Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "122d145a",
        "outputId": "34318895-d083-4f0b-a574-b06cd211e84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore results successfully saved to /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/bert_scores_combined_results.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Define the output file path in Google Drive\n",
        "output_excel_path = os.path.join(base_path, 'bert_scores_combined_results.xlsx')\n",
        "\n",
        "try:\n",
        "    # Save the DataFrame to an Excel file\n",
        "    bert_scores_combined_df.to_excel(output_excel_path, index=False)\n",
        "    print(f\"BERTScore results successfully saved to {output_excel_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving BERTScore results to Excel: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26296232"
      },
      "source": [
        "## 32-Calculate and display average BERT scores per case study\n",
        "\n",
        "### Subtask:\n",
        "Calculate the average Precision, Recall, and F1 scores for each case study across all iteration comparisons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f36b46c3"
      },
      "source": [
        "**Reasoning**:\n",
        "Group the `bert_scores_combined_df` DataFrame by 'Case Study' and calculate the mean of the BERTScore columns to get the average scores for each case study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "66718105",
        "outputId": "ecb019fd-6ec1-4b1e-e9c7-e57e9adb46d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Scores per Case Study (I1 vs B1):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Precision (Combined)  Recall (Combined)  F1 Score (Combined)\n",
              "Case Study                                                              \n",
              "CS1                     0.828892           0.848880             0.838767\n",
              "CS10                    0.825173           0.849242             0.837035\n",
              "CS2                     0.839137           0.849103             0.844091\n",
              "CS3                     0.820351           0.828075             0.824195\n",
              "CS4                     0.795311           0.811406             0.803278\n",
              "CS5                     0.823095           0.844350             0.833588\n",
              "CS6                     0.818403           0.825697             0.822034\n",
              "CS7                     0.797742           0.804377             0.801046\n",
              "CS8                     0.811500           0.830512             0.820896\n",
              "CS9                     0.824759           0.846670             0.835571"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97680e87-d5df-4aca-ae58-22ef5a6057ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision (Combined)</th>\n",
              "      <th>Recall (Combined)</th>\n",
              "      <th>F1 Score (Combined)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case Study</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CS1</th>\n",
              "      <td>0.828892</td>\n",
              "      <td>0.848880</td>\n",
              "      <td>0.838767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS10</th>\n",
              "      <td>0.825173</td>\n",
              "      <td>0.849242</td>\n",
              "      <td>0.837035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS2</th>\n",
              "      <td>0.839137</td>\n",
              "      <td>0.849103</td>\n",
              "      <td>0.844091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS3</th>\n",
              "      <td>0.820351</td>\n",
              "      <td>0.828075</td>\n",
              "      <td>0.824195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS4</th>\n",
              "      <td>0.795311</td>\n",
              "      <td>0.811406</td>\n",
              "      <td>0.803278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS5</th>\n",
              "      <td>0.823095</td>\n",
              "      <td>0.844350</td>\n",
              "      <td>0.833588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS6</th>\n",
              "      <td>0.818403</td>\n",
              "      <td>0.825697</td>\n",
              "      <td>0.822034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS7</th>\n",
              "      <td>0.797742</td>\n",
              "      <td>0.804377</td>\n",
              "      <td>0.801046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS8</th>\n",
              "      <td>0.811500</td>\n",
              "      <td>0.830512</td>\n",
              "      <td>0.820896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS9</th>\n",
              "      <td>0.824759</td>\n",
              "      <td>0.846670</td>\n",
              "      <td>0.835571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97680e87-d5df-4aca-ae58-22ef5a6057ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97680e87-d5df-4aca-ae58-22ef5a6057ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97680e87-d5df-4aca-ae58-22ef5a6057ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4da3e9c3-0592-46f4-b668-93524b5316b5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4da3e9c3-0592-46f4-b668-93524b5316b5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4da3e9c3-0592-46f4-b668-93524b5316b5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c8aba2b3-095d-4633-b5b9-6fc31a2d4662\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('average_bert_scores_per_case_study')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c8aba2b3-095d-4633-b5b9-6fc31a2d4662 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('average_bert_scores_per_case_study');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "average_bert_scores_per_case_study",
              "summary": "{\n  \"name\": \"average_bert_scores_per_case_study\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Case Study\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"CS8\",\n          \"CS10\",\n          \"CS5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision (Combined)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0135800579657113,\n        \"min\": 0.7953107953071594,\n        \"max\": 0.8391372561454773,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8115003705024719,\n          0.8251733779907227,\n          0.823095440864563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall (Combined)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01651053626865652,\n        \"min\": 0.8043773174285889,\n        \"max\": 0.8492419123649597,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.830512285232544,\n          0.8492419123649597,\n          0.8443504571914673\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score (Combined)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014701545285276752,\n        \"min\": 0.8010456562042236,\n        \"max\": 0.8440907001495361,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.820896327495575,\n          0.8370346426963806,\n          0.8335875272750854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Calculate the average BERT scores per case study - This will now show the single I1 vs B1 comparison per case study\n",
        "average_bert_scores_per_case_study = bert_scores_combined_df.groupby('Case Study')[['Precision (Combined)', 'Recall (Combined)', 'F1 Score (Combined)']].mean()\n",
        "\n",
        "# Display the table of average BERT scores\n",
        "print(\"BERT Scores per Case Study (I1 vs B1):\")\n",
        "display(average_bert_scores_per_case_study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5030876"
      },
      "source": [
        "## 33-Save Average BERT Scores Table\n",
        "\n",
        "### Subtask:\n",
        "Save the `average_bert_scores_per_case_study` DataFrame to an Excel file in the specified Google Drive folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfe29297"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the `to_excel` method of the pandas DataFrame to save the average BERT scores table to an Excel file in the user's Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "988a8bd6",
        "outputId": "118f69fa-96f1-43ac-cb62-d6b1bebe7f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BERT scores table successfully saved to /content/drive/My Drive/Colab Notebooks/BERTScore/BaselineAnalysis/average_bert_scores_per_case_study.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Define the output file path for the average scores table in Google Drive\n",
        "output_average_excel_path = os.path.join(base_path, 'average_bert_scores_per_case_study.xlsx')\n",
        "\n",
        "try:\n",
        "    # Save the DataFrame to an Excel file\n",
        "    average_bert_scores_per_case_study.to_excel(output_average_excel_path)\n",
        "    print(f\"Average BERT scores table successfully saved to {output_average_excel_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving average BERT scores table to Excel: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "AQlr98G6XPEH"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}